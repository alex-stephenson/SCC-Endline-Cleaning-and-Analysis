HHH_older = ifelse(!is.na(HHH_age_final) & HHH_age_final >= 55, 'yes',
ifelse(!is.na(HHH_age_final) & HHH_age_final < 55, 'no', '')),
HHH_age_final = ifelse(resp_HHH == 'yes', resp_age,
ifelse(resp_HHH == 'no', HHH_age, NA)),
HHH_gender_final = ifelse(resp_HHH == 'yes', resp_gender,
ifelse(resp_HHH == 'no', HHH_gender, NA)),
HHH_age_gender_category = ifelse(HHH_age_final < 50 & HHH_gender_final == 'male', '18-49 male',
ifelse(HHH_age_final < 50 & HHH_gender_final == 'female', '18-49 female',
ifelse(HHH_age_final >= 50 & HHH_age_final < 70 & HHH_gender_final == 'male', '50-69 male',
ifelse(HHH_age_final >= 50 & HHH_age_final < 70 & HHH_gender_final == 'female', '50-69 female',
ifelse(HHH_age_final >= 70 & HHH_gender_final == 'male', '70+ male', '70+ female')))))
) %>%
relocate(savings_Have, .after = Savings) %>%
relocate(debt_amnt_Have, .after = debt_amnt) %>%
relocate(Big_size_HH, .after = HH_size) %>%
relocate(low_income, .after = average_monthly_income)
cleaned_data <- cleaned_data %>%
mutate(
TotalHHEXP1 = as.numeric(ExpFood) + as.numeric(ExpFood_Debt) + as.numeric(ExpNFDebt) +
as.numeric(ExpNFMed) + as.numeric(ExpNFWat) + as.numeric(ExpNFCstrc) +
as.numeric(ExpNFCloth) + as.numeric(ExpNFFuel) + as.numeric(ExpNFEdu) +
as.numeric(ExpNFKhat) + as.numeric(ExpNFOther) + as.numeric(ExpNFRent),
ExpFoodProportion1 = ifelse(!is.na(ExpFood), as.numeric(ExpFood) / TotalHHEXP1 * 100, 0),
ExpNFMedProportion1 = ifelse(!is.na(ExpNFMed), as.numeric(ExpNFMed) / TotalHHEXP1 * 100, 0),
ExpNFCstrcProportion1 = ifelse(!is.na(ExpNFCstrc), as.numeric(ExpNFCstrc) / TotalHHEXP1 * 100, 0),
ExpNFClothProportion1 = ifelse(!is.na(ExpNFCloth), as.numeric(ExpNFCloth) / TotalHHEXP1 * 100, 0),
ExpNFWatProportion1 = ifelse(!is.na(ExpNFWat), as.numeric(ExpNFWat) / TotalHHEXP1 * 100, 0),
ExpFood_DebtProportion1 = ifelse(!is.na(ExpFood_Debt), as.numeric(ExpFood_Debt) / TotalHHEXP1 * 100, 0),
ExpNFDebtProportion1 = ifelse(!is.na(ExpNFDebt), as.numeric(ExpNFDebt) / TotalHHEXP1 * 100, 0),
TotalDebt = rowSums(dplyr::select(., ExpFood_Debt, ExpNFDebt), na.rm = TRUE),
ExpTotalDebtProportion1 = ifelse(TotalDebt == 0, 0, TotalDebt / TotalHHEXP1 * 100),
ExpNFFuelProportion1 = ifelse(!is.na(ExpNFFuel), as.numeric(ExpNFFuel) / TotalHHEXP1 * 100, 0),
ExpNFEduProportion1 = ifelse(!is.na(ExpNFEdu), as.numeric(ExpNFEdu) / TotalHHEXP1 * 100, 0),
ExpNFRentProportion1 = ifelse(!is.na(ExpNFRent), as.numeric(ExpNFRent) / TotalHHEXP1 * 100, 0),
ExpNFKhatProportion1 = ifelse(!is.na(ExpNFKhat), as.numeric(ExpNFKhat) / TotalHHEXP1 * 100, 0),
ExpNFOtherProportion1 = ifelse(!is.na(ExpNFOther), as.numeric(ExpNFOther) / TotalHHEXP1 * 100, 0),
NFOther_NFKhat = rowSums(dplyr::select(., ExpNFOther, ExpNFKhat), na.rm = TRUE),
ExpNFOther_NFKhatProportion1 = ifelse(NFOther_NFKhat == 0, 0, NFOther_NFKhat / TotalHHEXP1 * 100),
savings_amnt = ifelse(Savings > 0, Savings, 0),
savings_Have = ifelse(Savings > 0, 'yes', ifelse(savings == 0, 'no', '')),
debt_amnt_Have = ifelse(debt_amnt > 0, debt_amnt, 0),
debt1 = ifelse(debt_amnt > 0, 'yes', ifelse(debt_amnt == 0, 'no', '')),
average_monthly_income_pp1 = ifelse(!is.na(average_monthly_income),
average_monthly_income / HH_size, NA),
Big_size_HH = ifelse(HH_size > 6, 'yes', 'no'),
low_income = ifelse(!is.na(average_monthly_income) & average_monthly_income < 130, 'yes',
ifelse(!is.na(average_monthly_income) & average_monthly_income >= 130, 'no', '')),
HHH_older = ifelse(!is.na(HHH_age_final) & HHH_age_final >= 55, 'yes',
ifelse(!is.na(HHH_age_final) & HHH_age_final < 55, 'no', '')),
HHH_age_final = ifelse(resp_HHH == 'yes', resp_age,
ifelse(resp_HHH == 'no', HHH_age, NA)),
HHH_gender_final = ifelse(resp_HHH == 'yes', resp_gender,
ifelse(resp_HHH == 'no', HHH_gender, NA)),
HHH_age_gender_category = ifelse(HHH_age_final < 50 & HHH_gender_final == 'male', '18-49 male',
ifelse(HHH_age_final < 50 & HHH_gender_final == 'female', '18-49 female',
ifelse(HHH_age_final >= 50 & HHH_age_final < 70 & HHH_gender_final == 'male', '50-69 male',
ifelse(HHH_age_final >= 50 & HHH_age_final < 70 & HHH_gender_final == 'female', '50-69 female',
ifelse(HHH_age_final >= 70 & HHH_gender_final == 'male', '70+ male', '70+ female')))))
) %>%
relocate(savings_Have, .after = Savings) %>%
relocate(debt_amnt_Have, .after = debt_amnt) %>%
relocate(Big_size_HH, .after = HH_size) %>%
relocate(low_income, .after = average_monthly_income)
cleaned_data <- cleaned_data %>%
mutate(
TotalHHEXP1 = as.numeric(ExpFood) + as.numeric(ExpFood_Debt) + as.numeric(ExpNFDebt) +
as.numeric(ExpNFMed) + as.numeric(ExpNFWat) + as.numeric(ExpNFCstrc) +
as.numeric(ExpNFCloth) + as.numeric(ExpNFFuel) + as.numeric(ExpNFEdu) +
as.numeric(ExpNFKhat) + as.numeric(ExpNFOther) + as.numeric(ExpNFRent),
ExpFoodProportion1 = ifelse(!is.na(ExpFood), as.numeric(ExpFood) / TotalHHEXP1 * 100, 0),
ExpNFMedProportion1 = ifelse(!is.na(ExpNFMed), as.numeric(ExpNFMed) / TotalHHEXP1 * 100, 0),
ExpNFCstrcProportion1 = ifelse(!is.na(ExpNFCstrc), as.numeric(ExpNFCstrc) / TotalHHEXP1 * 100, 0),
ExpNFClothProportion1 = ifelse(!is.na(ExpNFCloth), as.numeric(ExpNFCloth) / TotalHHEXP1 * 100, 0),
ExpNFWatProportion1 = ifelse(!is.na(ExpNFWat), as.numeric(ExpNFWat) / TotalHHEXP1 * 100, 0),
ExpFood_DebtProportion1 = ifelse(!is.na(ExpFood_Debt), as.numeric(ExpFood_Debt) / TotalHHEXP1 * 100, 0),
ExpNFDebtProportion1 = ifelse(!is.na(ExpNFDebt), as.numeric(ExpNFDebt) / TotalHHEXP1 * 100, 0),
TotalDebt = rowSums(dplyr::select(., ExpFood_Debt, ExpNFDebt), na.rm = TRUE),
ExpTotalDebtProportion1 = ifelse(TotalDebt == 0, 0, TotalDebt / TotalHHEXP1 * 100),
ExpNFFuelProportion1 = ifelse(!is.na(ExpNFFuel), as.numeric(ExpNFFuel) / TotalHHEXP1 * 100, 0),
ExpNFEduProportion1 = ifelse(!is.na(ExpNFEdu), as.numeric(ExpNFEdu) / TotalHHEXP1 * 100, 0),
ExpNFRentProportion1 = ifelse(!is.na(ExpNFRent), as.numeric(ExpNFRent) / TotalHHEXP1 * 100, 0),
ExpNFKhatProportion1 = ifelse(!is.na(ExpNFKhat), as.numeric(ExpNFKhat) / TotalHHEXP1 * 100, 0),
ExpNFOtherProportion1 = ifelse(!is.na(ExpNFOther), as.numeric(ExpNFOther) / TotalHHEXP1 * 100, 0),
NFOther_NFKhat = rowSums(dplyr::select(., ExpNFOther, ExpNFKhat), na.rm = TRUE),
ExpNFOther_NFKhatProportion1 = ifelse(NFOther_NFKhat == 0, 0, NFOther_NFKhat / TotalHHEXP1 * 100),
savings_amnt = ifelse(Savings > 0, Savings, 0),
savings_Have = ifelse(Savings > 0, 'yes', ifelse(Savings == 0, 'no', '')),
debt_amnt_Have = ifelse(debt_amnt > 0, debt_amnt, 0),
debt1 = ifelse(debt_amnt > 0, 'yes', ifelse(debt_amnt == 0, 'no', '')),
average_monthly_income_pp1 = ifelse(!is.na(average_monthly_income),
average_monthly_income / HH_size, NA),
Big_size_HH = ifelse(HH_size > 6, 'yes', 'no'),
low_income = ifelse(!is.na(average_monthly_income) & average_monthly_income < 130, 'yes',
ifelse(!is.na(average_monthly_income) & average_monthly_income >= 130, 'no', '')),
HHH_older = ifelse(!is.na(HHH_age_final) & HHH_age_final >= 55, 'yes',
ifelse(!is.na(HHH_age_final) & HHH_age_final < 55, 'no', '')),
HHH_age_final = ifelse(resp_HHH == 'yes', resp_age,
ifelse(resp_HHH == 'no', HHH_age, NA)),
HHH_gender_final = ifelse(resp_HHH == 'yes', resp_gender,
ifelse(resp_HHH == 'no', HHH_gender, NA)),
HHH_age_gender_category = ifelse(HHH_age_final < 50 & HHH_gender_final == 'male', '18-49 male',
ifelse(HHH_age_final < 50 & HHH_gender_final == 'female', '18-49 female',
ifelse(HHH_age_final >= 50 & HHH_age_final < 70 & HHH_gender_final == 'male', '50-69 male',
ifelse(HHH_age_final >= 50 & HHH_age_final < 70 & HHH_gender_final == 'female', '50-69 female',
ifelse(HHH_age_final >= 70 & HHH_gender_final == 'male', '70+ male', '70+ female')))))
) %>%
relocate(savings_Have, .after = Savings) %>%
relocate(debt_amnt_Have, .after = debt_amnt) %>%
relocate(Big_size_HH, .after = HH_size) %>%
relocate(low_income, .after = average_monthly_income)
cleaned_data <- cleaned_data %>%
mutate(ecmen1 = ifelse(TotalHHEXP-(ExpNFKhat + ExpNFOther) > MEB, 1, 0))
cleaned_data <- cleaned_data %>%
mutate(Current_Status = case_when(
fsl_fcs_cat == "Acceptable" & fsl_rcsi_score < 4 ~ 1,
fsl_fcs_cat == "Acceptable" & fsl_rcsi_score >= 4 ~ 2,
fsl_fcs_cat == "Borderline" ~ 3,
fsl_fcs_cat == "Poor" ~ 4
))
# Assign value labels for Current Status
Current_Status_labels <- c(
"1" = "Food Secure",
"2" = "Marginally Food Secure",
"3" = "Moderately Food Insecure",
"4" = "Severely Food Insecure"
)
# Convert Current_Status to a factor with labels
cleaned_data$Current_Status <- factor(cleaned_data$Current_Status,
levels = c(1, 2, 3, 4),
labels = Current_Status_labels)
# Create new column current_status_numeric with 1, 2, 3, 4 based on Current_Status factor
cleaned_data <- cleaned_data %>%
mutate(current_status_numeric = as.numeric(Current_Status))
# Economic Vulnerability (ECMEN)
# ECMEN Calculation
cleaned_data <- cleaned_data %>%
mutate(SMEB = ifelse(region == 'banaadir', 151,
NA))
cleaned_data <- cleaned_data %>%
mutate(
ECMEN = case_when(
TotalHHEXP1-(ExpNFKhat + ExpNFOther) > MEB ~ 1,
TotalHHEXP1-(ExpNFKhat + ExpNFOther) >= SMEB & TotalHHEXP1-(ExpNFKhat + ExpNFOther) <= MEB ~ 3,
TotalHHEXP1-(ExpNFKhat + ExpNFOther) <= SMEB ~ 4
)
)
#Classify Livelihood Coping Strategies (LCS)
cleaned_data <- cleaned_data %>%
mutate(LCS_class = case_when(
fsl_lcsi_cat == "None" ~ 1,
fsl_lcsi_cat == "Stress" ~ 2,
fsl_lcsi_cat == "Crisis" ~ 3,
fsl_lcsi_cat == "Emergency" ~ 4
))
# Combine Coping Capacity Components
cleaned_data <- cleaned_data %>%
mutate(Coping_Capacity = pmax(ECMEN, LCS_class, na.rm = TRUE))
# Assign value labels for Coping Capacity
Coping_Capacity_labels <- c(
"1" = "Food Secure",
"2" = "Marginally Food Secure",
"3" = "Moderately Food Insecure",
"4" = "Severely Food Insecure"
)
# Convert Coping_Capacity to a factor with labels
cleaned_data$Coping_Capacity <- factor(cleaned_data$Coping_Capacity,
levels = c(1, 2, 3, 4),
labels = Coping_Capacity_labels)
# Create new column coping_capacity_numeric with 1, 2, 3, 4 based on Coping_Capacity factor
cleaned_data <- cleaned_data %>%
mutate(coping_capacity_numeric = as.numeric(Coping_Capacity))
cleaned_data <- cleaned_data %>%
mutate(
ECMEN_numeric = as.numeric(as.character(ECMEN)),
Mean_coping_capacity_ECMEN = rowMeans(cbind(coping_capacity_numeric, ECMEN_numeric), na.rm = TRUE)
)
# Calculate CARI (Comprehensive Approach to Resilience Index)
# Ensure both columns are numeric
cleaned_data <- cleaned_data %>%
mutate(
Mean_coping_capacity_ECMEN_numeric = as.numeric(as.character(Mean_coping_capacity_ECMEN)),
CARI_unrounded_ECMEN = rowMeans(cbind(current_status_numeric, Mean_coping_capacity_ECMEN_numeric), na.rm = TRUE),
CARI_ECMEN = round(CARI_unrounded_ECMEN)
)
# Assign value labels for CARI_ECMEN
CARI_ECMEN_labels <- c(
"1" = "Food Secure",
"2" = "Marginally Food Secure",
"3" = "Moderately Food Insecure",
"4" = "Severely Food Insecure"
)
# Optional: Convert CARI_ECMEN to a factor with labels
cleaned_data$CARI_ECMEN <- factor(cleaned_data$CARI_ECMEN,
levels = c(1, 2, 3, 4),
labels = CARI_ECMEN_labels)
sampling_frame <- read_csv("inputs/weights.csv")
cleaned_data_weighted <- cleaned_data %>%
add_weights(sampling_frame,
strata_column_dataset = "district",
strata_column_sample = "strata.names",
population_column = "population")
# writing the raw and cleaned data
data<-list(questions =questions,choices=choices,raw_data=raw_data,cleaned_data=cleaned_data_weighted)
writexl::write_xlsx(data,paste("output/clean_and_raw.xlsx"))
rm(list = ls())
library(tidyverse)
library(cleaningtools)
library(analysistools)
library(presentresults)
library(readxl)
# write the aggregation file with a timestamp to more easily keep track of different versions
date_time_now <- format(Sys.time(), "%a_%b_%d_%Y_%H%M%S")
##############################################################################
########################## Load the Data and Survey ##########################
##############################################################################
# load datasets for processing
file_path <- "output/clean_and_raw.xlsx"
main_data <- read_excel(file_path, 'cleaned_data')
raw_data <- read_excel("inputs/as_raw_data.xlsx") %>%
select(-savings)
## tool
kobo_tool_name <- "inputs/IRF_ENDLINE_TOOL_FEB2025.xlsx"
kobo_survey <- read_excel(kobo_tool_name, sheet = "survey") %>%
mutate(type = str_squish(type)) %>%
mutate(`label::English` = ifelse(
`label::English` == "If yes, which goods and commodity prices have increased?" & name == "community_price_goods", "If yes, which community goods and commodity prices have increased?", `label::English`))
kobo_choice <- read_excel(kobo_tool_name, sheet = "choices") %>%
distinct(list_name, name, .keep_all = T) %>%
filter(list_name != "settlement" | list_name == "settlement" & name %in% main_data$settlement) %>%
filter(name != "Bulsho IDP")
## load in the LOA
loa <- readxl::read_excel("inputs/scc_endline_loa.xlsx")
deletion <- read_excel("inputs/as_deletion_log.xlsx")
combined_clogs <- read_excel("combined clogs/corrected_combined cleaning clogs.xlsx") %>%
filter(! uuid %in% deletion$uuid)
############################### create HH survey design and analysis #################################################
#main_data_cols <- main_data %>%
#  select(any_of(contains(loa_questions)), weights)
SCC_endline_Survey_Design <- main_data %>%
srvyr::as_survey_design(., strata = "district", weights = weights)
my_analysis <- create_analysis(SCC_endline_Survey_Design, sm_separator = "/", loa = loa)
rm(list = ls())
library(tidyverse)
library(cleaningtools)
library(analysistools)
library(presentresults)
library(readxl)
# write the aggregation file with a timestamp to more easily keep track of different versions
date_time_now <- format(Sys.time(), "%a_%b_%d_%Y_%H%M%S")
##############################################################################
########################## Load the Data and Survey ##########################
##############################################################################
# load datasets for processing
file_path <- "output/clean_and_raw.xlsx"
main_data <- read_excel(file_path, 'cleaned_data')
raw_data <- read_excel("inputs/as_raw_data.xlsx") %>%
select(-savings)
## tool
kobo_tool_name <- "inputs/IRF_ENDLINE_TOOL_FEB2025.xlsx"
kobo_survey <- read_excel(kobo_tool_name, sheet = "survey") %>%
mutate(type = str_squish(type)) %>%
mutate(`label::English` = ifelse(
`label::English` == "If yes, which goods and commodity prices have increased?" & name == "community_price_goods", "If yes, which community goods and commodity prices have increased?", `label::English`))
kobo_choice <- read_excel(kobo_tool_name, sheet = "choices") %>%
distinct(list_name, name, .keep_all = T) %>%
filter(list_name != "settlement" | list_name == "settlement" & name %in% main_data$settlement) %>%
filter(name != "Bulsho IDP")
## load in the LOA
loa <- readxl::read_excel("inputs/scc_endline_loa.xlsx")
deletion <- read_excel("inputs/as_deletion_log.xlsx")
combined_clogs <- read_excel("combined clogs/corrected_combined cleaning clogs.xlsx") %>%
filter(! uuid %in% deletion$uuid)
############################### create HH survey design and analysis #################################################
#main_data_cols <- main_data %>%
#  select(any_of(contains(loa_questions)), weights)
SCC_endline_Survey_Design <- main_data %>%
srvyr::as_survey_design(., strata = "district", weights = weights)
my_analysis <- create_analysis(SCC_endline_Survey_Design, sm_separator = "/", loa = loa)
raw_data$low_income
my_analysis <- create_analysis(SCC_endline_Survey_Design, sm_separator = "/", loa = loa)
main_data$suggestions
my_analysis <- create_analysis(SCC_endline_Survey_Design, sm_separator = "/", loa = loa)
rm(list = ls())
library(tidyverse)
library(cleaningtools)
library(analysistools)
library(presentresults)
library(readxl)
# write the aggregation file with a timestamp to more easily keep track of different versions
date_time_now <- format(Sys.time(), "%a_%b_%d_%Y_%H%M%S")
##############################################################################
########################## Load the Data and Survey ##########################
##############################################################################
# load datasets for processing
file_path <- "output/clean_and_raw.xlsx"
main_data <- read_excel(file_path, 'cleaned_data')
raw_data <- read_excel("inputs/as_raw_data.xlsx") %>%
select(-savings)
## tool
kobo_tool_name <- "inputs/IRF_ENDLINE_TOOL_FEB2025.xlsx"
kobo_survey <- read_excel(kobo_tool_name, sheet = "survey") %>%
mutate(type = str_squish(type)) %>%
mutate(`label::English` = ifelse(
`label::English` == "If yes, which goods and commodity prices have increased?" & name == "community_price_goods", "If yes, which community goods and commodity prices have increased?", `label::English`))
kobo_choice <- read_excel(kobo_tool_name, sheet = "choices") %>%
distinct(list_name, name, .keep_all = T) %>%
filter(list_name != "settlement" | list_name == "settlement" & name %in% main_data$settlement) %>%
filter(name != "Bulsho IDP")
## load in the LOA
loa <- readxl::read_excel("inputs/scc_endline_loa.xlsx")
deletion <- read_excel("inputs/as_deletion_log.xlsx")
combined_clogs <- read_excel("combined clogs/corrected_combined cleaning clogs.xlsx") %>%
filter(! uuid %in% deletion$uuid)
############################### create HH survey design and analysis #################################################
#main_data_cols <- main_data %>%
#  select(any_of(contains(loa_questions)), weights)
SCC_endline_Survey_Design <- main_data %>%
srvyr::as_survey_design(., strata = "district", weights = weights)
my_analysis <- create_analysis(SCC_endline_Survey_Design, sm_separator = "/", loa = loa)
loa
## load in the LOA
loa <- readxl::read_excel("inputs/scc_endline_loa.xlsx") %>%
filter(analysis_var != "final_lcsi_cat")
my_analysis <- create_analysis(SCC_endline_Survey_Design, sm_separator = "/", loa = loa)
results_table <- my_analysis$results_table
review_kobo_labels_results <- review_kobo_labels(kobo_survey,
kobo_choice,
label_column = "label::English",
results_table = results_table)
label_dictionary <- create_label_dictionary(kobo_survey,
kobo_choice,
label_column = "label::English",
results_table = results_table)
results_table_labeled <- add_label_columns_to_results_table(
results_table,
label_dictionary
)
## this function pivots it wider so we have each analysis variable as a row and each group as a column
group_wide_results_table <- results_table_labeled %>%
create_table_variable_x_group()
create_xlsx_variable_x_group(group_wide_results_table, file_path = "output/results_table_long.xlsx", overwrite = T)
## this one pivots wider so we have each group as a row and each analysis variable as a column
analysis_wide_results_table <- results_table_labeled %>%
create_table_group_x_variable()
create_xlsx_group_x_variable(analysis_wide_results_table, file_path = "output/results_table_wide.xlsx", overwrite = T)
cols_to_remove <- c("consent_no", "enumerator_sensitivity", "deviceid", "audit", "enumerator_ID",
"resp_phone", "resp_age", "_submission_time", "_validation_status",
"_notes", "_status", "_submitted_by", "__version__", "_tags", "_index", "audit_URL")
raw_data_no_pii <- raw_data %>%
select(-any_of(cols_to_remove))
main_data_no_pii <- main_data %>%
select(-any_of(cols_to_remove))
deletion <- deletion %>%
left_join(raw_data %>%  select(`_uuid`, enumerator_ID), by = join_by("uuid" == "_uuid"))
final_output <- list(raw_data = raw_data_no_pii, cleaned_data = main_data_no_pii, survey = kobo_survey, choices = kobo_choice, deletion_log = deletion, cleaning_logs = combined_clogs)
writexl::write_xlsx(final_output, "output/all_data_logbook_3.xlsx")
df_main_analysis_table <- presentresults::create_table_variable_x_group(results_table = results_table, value_columns = "stat")
# Replace NA values in list columns with NULL
df_main_analysis_table <- df_main_analysis_table %>%
mutate(across(where(is.list), ~ map(.x, ~ ifelse(is.na(.x), list(NULL), .x))))
df_main_analysis_table <- df_main_analysis_table %>%
mutate(across(where(~ !is.list(.x) & is.numeric(.x)), ~ replace(.x, is.na(.x), NA))) %>%
mutate(across(where(~ !is.list(.x) & !is.numeric(.x)), ~ ifelse(is.na(.x), "NA", .x)))
# Step 8: Export the main analysis percentages table -------------------------
presentresults::create_xlsx_variable_x_group(
table_group_x_variable = df_main_analysis_table,
file_path = paste0("output/results_table_long_v2.xlsx"),
value_columns = c("stat","n"),
overwrite = TRUE
)
# Step 9: Create and process the statistics table (counts: n, N, weighted) ----
# Ensure `df_data$results_table` is used correctly for creating a table by group
df_stats_table <- presentresults::create_table_variable_x_group(
results_table = df_data$results_table,
value_columns = c("n")
)
### begin new code
df_main_analysis_table <- presentresults::create_table_variable_x_group(results_table = results_table_labeled, value_columns = "stat")
# Replace NA values in list columns with NULL
df_main_analysis_table <- df_main_analysis_table %>%
mutate(across(where(is.list), ~ map(.x, ~ ifelse(is.na(.x), list(NULL), .x))))
# # Replace NA values in non-list columns with "NA"
# df_main_analysis_table <- df_main_analysis_table %>%
#   mutate(across(where(~ !is.list(.x)), ~ ifelse(is.na(.x), "NA", .x)))
df_main_analysis_table <- df_main_analysis_table %>%
mutate(across(where(~ !is.list(.x) & is.numeric(.x)), ~ replace(.x, is.na(.x), NA))) %>%
mutate(across(where(~ !is.list(.x) & !is.numeric(.x)), ~ ifelse(is.na(.x), "NA", .x)))
# Step 8: Export the main analysis percentages table -------------------------
presentresults::create_xlsx_variable_x_group(
table_group_x_variable = df_main_analysis_table,
file_path = paste0("output/results_table_long_v2.xlsx"),
value_columns = c("stat","n"),
overwrite = TRUE
)
# Step 9: Create and process the statistics table (counts: n, N, weighted) ----
# Ensure `df_data$results_table` is used correctly for creating a table by group
df_stats_table <- presentresults::create_table_variable_x_group(
results_table = results_table_labeled,
value_columns = c("n")
)
# Handle NA values in df_stats_table
df_stats_table <- df_stats_table %>%
mutate(across(where(is.list), ~ map(.x, ~ ifelse(is.na(.x), list(NULL), .x)))) %>%
mutate(across(where(~ !is.list(.x)), ~ ifelse(is.na(.x), "", .x)))
# Export the processed stats table to Excel
presentresults::create_xlsx_variable_x_group(
table_group_x_variable = df_stats_table,  # Use the processed table
file_path = paste0("C:\\Users\\Mercy Kalondu\\OneDrive - ACTED\\Bureau\\old laptop files\\REACH WORK\\SOM 2406 SCC endline analysis Phase 2/", butteR::date_file_prefix(), "_main_analysis_table.xlsx"),
value_columns = c("n"),
overwrite = TRUE
)
# Export the processed stats table to Excel
presentresults::create_xlsx_variable_x_group(
table_group_x_variable = df_stats_table,  # Use the processed table
file_path = paste0("output/results_table_long_v3.xlsx"),
value_columns = c("n"),
overwrite = TRUE
)
df_stats_table <- presentresults::create_table_variable_x_group(
results_table = results_table_labeled,
value_columns = c("n")
)
# Handle NA values in df_stats_table
df_stats_table <- df_stats_table %>%
mutate(across(where(is.list), ~ map(.x, ~ ifelse(is.na(.x), list(NULL), .x)))) %>%
mutate(across(where(~ !is.list(.x)), ~ ifelse(is.na(.x), "", .x)))
# Export the processed stats table to Excel
presentresults::create_xlsx_variable_x_group(
table_group_x_variable = df_stats_table,  # Use the processed table
file_path = paste0("output/results_table_long_v3.xlsx"),
value_columns = c("n"),
overwrite = TRUE
)
# Step 8: Export the main analysis percentages table -------------------------
presentresults::create_xlsx_variable_x_group(
table_group_x_variable = df_main_analysis_table,
file_path = paste0("output/results_table_long_percent.xlsx"),
value_columns = c("stat","n"),
overwrite = TRUE
)
# Step 9: Create and process the statistics table (counts: n, N, weighted) ----
# Ensure `df_data$results_table` is used correctly for creating a table by group
df_stats_table <- presentresults::create_table_variable_x_group(
results_table = results_table_labeled,
value_columns = c("n")
)
# Handle NA values in df_stats_table
df_stats_table <- df_stats_table %>%
mutate(across(where(is.list), ~ map(.x, ~ ifelse(is.na(.x), list(NULL), .x)))) %>%
mutate(across(where(~ !is.list(.x)), ~ ifelse(is.na(.x), "", .x)))
# Export the processed stats table to Excel
presentresults::create_xlsx_variable_x_group(
table_group_x_variable = df_stats_table,  # Use the processed table
file_path = paste0("output/results_table_long_values.xlsx"),
value_columns = c("n"),
overwrite = TRUE
)
?create_xlsx_variable_x_group
presentresults::create_xlsx_group_x_variable(
table_group_x_variable = df_main_analysis_table,
file_path = paste0("output/results_table_wide_percent.xlsx"),
value_columns = c("stat","n"),
overwrite = TRUE
)
presentresults::create_xlsx_group_x_variable(
table_group_x_variable = df_main_analysis_table,
file_path = paste0("output/results_table_wide_percent.xlsx"),
overwrite = TRUE
)
df_main_analysis_table
df_wide_analysis_table <- presentresults::create_table_group_x_variable(results_table = results_table_labeled, value_columns = "stat")
View(df_wide_analysis_table)
presentresults::create_xlsx_group_x_variable(
table_group_x_variable = df_wide_analysis_table,
file_path = paste0("output/results_table_wide_percent.xlsx"),
overwrite = TRUE
)
df_wide_analysis_table <- presentresults::create_table_group_x_variable(results_table = results_table_labeled,   value_columns = c("n"))
df_wide_analysis_table_num <- presentresults::create_table_group_x_variable(
results_table = results_table_labeled, value_columns = c("n"))
presentresults::create_xlsx_group_x_variable(
table_group_x_variable = df_wide_analysis_table_num,
file_path = paste0("output/results_table_wide_values.xlsx"),
overwrite = TRUE
)
cleaned_data_weighted
main_data <- read_excel(file_path, 'cleaned_data')
raw_data <- read_excel("inputs/as_raw_data.xlsx") %>%
select(-savings)
raw_data %>% colnames()
raw_data_cols <- raw_data %>% colnames()
clean_data_cols <- main_data %>% colnames)=
clean_data_cols <- main_data %>% colnames()
data.frame(x = clean_data_cols) %>% filter(!x %in% raw_data_cols)
data.frame(x = clean_data_cols) %>% filter(!x %in% raw_data_cols) %>% View()
cleaned_data$CARI_ECMEN
readxl::read_excel("inputs/scc_endline_loa.xlsx") %>%
filter(analysis_var == "final_lcsi_cat")
main_data %>% select(CARI_ECMEN)
library(ImpactFunctions)
my_raw_dataset <- ImpactFunctions::get_kobo_data(asset_id = "a78BPkkB3ZDwihdL5uqd5J", un = "abdiramania")
my_raw_dataset <- ImpactFunctions::get_kobo_data(asset_id = "a78BPkkB3ZDwihdL5uqd5J", un = "alex_stephenson")
my_raw_dataset <- ImpactFunctions::get_kobo_data(asset_id = "a78BPkkB3ZDwihdL5uqd5J", un = "abdirahmanaia")
my_raw_dataset
my_raw_dataset
mindur <- 15
maxdur <- 50
kobo_data_metadata <- get_kobo_metadata(dataset = my_raw_dataset, asset_id = "a78BPkkB3ZDwihdL5uqd5J")
kobo_settings_output <- robotoolbox::kobo_settings()
kobo_data_metadata <- get_kobo_metadata(dataset = my_raw_dataset, asset_id = "a78BPkkB3ZDwihdL5uqd5J")
kobo_data_metadata
kobo_data_metadata$data_in_processing
